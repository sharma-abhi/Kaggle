y <- c(5.12, 3.93, 2.67, 1.87, 0.52, 0.08, 0.93, 2.05, 2.54, 3.87, 4.97)
knots <- 0
splineTerms <- sapply(knots, function(knot) (x > knot) * (x - knot))
xMat <- cbind(1, x, splineTerms)
fitMod <- lm(y ~ xMat - 1)
yhat <- predict(lm(y ~ xMat - 1))
summary(fitMod)
plot(x, y, frame=FALSE, pch=21, bg="lightblue", cex=2)
lines(x, yhat, col="red", lwd=2)
2.037 +1.02
k
rm(ls=list())
rm(list=ls())
library(MASS)
data(shuttle)
k <- factor((shuttle$use == "auto"))
k
k <- factor(as.numeric(shuttle$use == "auto"))
k
str(k)
levels(k)
k <- factor(as.numeric(shuttle$use == "auto"), levels="1", "0")
k
k <- factor(as.numeric(shuttle$use == "auto"), levels=c("1", "0"))
k
str(k)
fitMod <- glm(k ~ wind, data=shuttle, family="binomial")
summary(fitMod)
exp(fitMod$coef)
fitMod2 <- glm(k ~ wind + magn, data=shuttle, family="binomial")
summary(fitMod2)
fitMod$coef
fitMod2$coef
exp(fitMod2$coef)
(1-0.9684)/0.9684
head(shuttle)
str(shuttle)
k <- factor(as.numeric(shuttle$use == "noauto"))
k
fitMod <- glm(k ~ wind, data=shuttle, family="binomial")
summary(fitMod)
exp(fitMod)
exp(fitMod$coef)
str(k)
fitMod2 <- glm(k ~ wind + magn, data=shuttle, family="binomial")
summary(fitMod2)
expr(fitMod2$coef)
exp(fitMod2$coef)
fitMod2 <- glm(k ~ wind + magn -1, data=shuttle, family="binomial")
exp(fitMod2$coef)
fitMod <- glm(k ~ wind -1, data=shuttle, family="binomial")
exp(fitMod$coef)
(1-0.75)/0.75
(1-0.67)/0.67
data(InsectSprays)
modFit <- glm(spray ~ count, data=InsectSprays, family="poisson")
factor(InsectSprays$spray) == InsectSprays$spray
fitMod
fitMod <- glm(k ~ wind, data=shuttle, family="binomial")
exp(fitMod$coef
)
fitMod2 <- glm(k ~ wind + magn, data=shuttle, family="binomial")
exp(fitMod2$coef)
data(InsectSprays)
modFit <- glm(spray ~ count, data=InsectSprays, family="poisson")
str(InsectSprays)
data(InsectSprays)
modFit <- glm(spray ~., data=InsectSprays, family="poisson")
data(InsectSprays)
modFit <- glm(count ~., data=InsectSprays, family="poisson")
summary(count)
summary(modFit)
exp(modFit$coef)
data(InsectSprays)
modFit <- glm(count ~. -1, data=InsectSprays, family="poisson")
exp(modFit$coef)
14.5/15.33
2.037 - 1.024
library(MASS)
data(shuttle)
fitMod <- glm(use ~ wind, data=shuttle, family="binomial")
exp(fitMod$coeff)
library(MASS)
data(shuttle)
fitMod <- glm(use ~ wind -1, data=shuttle, family="binomial")
exp(fitMod$coeff)
0.777/0.753
x <- -5:5
y <- c(5.12, 3.93, 2.67, 1.87, 0.52, 0.08, 0.93, 2.05, 2.54, 3.87, 4.97)
knots <- 0
splineTerms <- sapply(knots, function(knot) (x > knot) * (x - knot))
xMat <- cbind(1, x, splineTerms)
fitMod <- lm(y ~ xMat - 1)
yhat <- predict(lm(y ~ xMat - 1))
summary(fitMod)
plot(x, y, frame=FALSE, pch=21, bg="lightblue", cex=2)
lines(x, yhat, col="red", lwd=2)
fitMod$coef[2] + fitMod$coef[3]
modFit <- glm(count ~  spray + offset(1), data=InsectSprays, family="poisson")
sim(InsectSprays)
dim(InsectSprays)
t <- seq(0,20,length=72)
t
modFit <- glm(count ~  spray + offset(t), data=InsectSprays, family="poisson")
summary(modFit)
modFit2 <- glm(count ~  spray + offset(log(10) + t), data=InsectSprays, family="poisson")
summary(modFit2)
library(swirl)
install.packages("swirl")
library(swirl)
swirl()
x1c <- simbias()
x1c
apply(x1c, 1, mean)
fit1 <- lm(Fertility ~ Agriculture, data=swiss)
fit3 <- update(fit1, Fertility ~ Agriculture + Examination + Education, data=swiss)
anova(fit1, fit3)
deviance(fit3)
d <- deviance(fit3)/43
n <- (deviance(fit1) - deviance(fit3))/2
n/d
pf(n/d, 2, 43, lower.tail = FALSE)
shapiro.test(fit3$residuals)
anova(fit1, fit3, fit5, fit6)
View(ravenData)
mdl <- glm(ravenWinNum ~ ravenScore, family="binomail", data=ravenData)
mdl <- glm(ravenWinNum ~ ravenScore, family="binomial", data=ravenData)
lodds <- predict(mdl, data.frame(ravenScore=c(0, 3, 6)))
lodds
exp(lodds)/(1 + exp(lodds))
summary(modl)
summary(mdl)
confint(mdl)
exp(confint(mdl))
anova(mdl)
qchisq(0, 95, 1)
qchisq(0.95, 1)
rpois(1000,50)
var(rpois(1000,50))
nxt()
View(hits)
class(hist[, 'date'])
class(hits[, 'date'])
as.integer(head(hits[, 'date']))
mdl <- glm(visits ~ date, family="poisson", data=hits)
summary)mdl
summary(mdl)
confint(mdl, 'date')
exp(confint(mdl, 'date'))
which.max(hits[, 'visits'])
hits[704]
hits[704,]
lambda <- mdl$fitted.values[704]
lambda
qpois(0.95, lambda)
mdl2 <- glm(visits ~ date, offset=log(visits + 1), family="poisson", data=hits)
mdl2 <- glm(simplystats ~ date, offset=log(visits + 1), family="poisson", data=hits)
summary(mdl2)
qpois(.95, mdl2$fitted.values[704])
path <- "C://Users//Abhijeet//Documents//GitHub//Kaggle//Titanic_Machine_Learning_from_Disaster//My Implementation"
if (getwd() != path) {setwd(path)}
# Step 1
## Fetching data from the training and testing datasets
inp_train <- read.csv(file="data/train.csv", header=TRUE, sep=",", quote="\"",
stringsAsFactors=FALSE, na.strings=c("NA",""))
inp_test <- read.csv(file="data/test.csv", header=TRUE, sep=",", quote="\"",
stringsAsFactors=FALSE, na.strings=c("NA",""))
train <- inp_train
test <- inp_test
test$Survived <- as.integer(NA) # Dummy value
test <- test[,names(train)]
test$Fare[which(is.na(test$Fare))] <- 0
merged_set <- rbind(train, test)
merged_set$Pclass <- factor(merged_set$Pclass)
merged_set$Sex <- factor(merged_set$Sex)
merged_set$Embarked <- factor(merged_set$Embarked)
first_name <- gsub("[A-Za-z '-]*, ", "", merged_set$Name)
Title <- gsub("[. *] .*","",first_name)
Title[Title=="Col" | Title=="Capt" | Title=="Major"] <- "Army"
Title[Title=="Sir"| Title=="Don" | Title=="Jonkheer" | Title=="Dona" |
Title=="the Countess" | Title=="Lady"] <- "Royal"
Title[Title=="Miss" | Title=="Mlle" | Title=="Ms"] <- "Non-royal Unmarried Female"
Title[Title=="Mrs" | Title=="Mme"] <- "Non-royal Married Female"
merged_set$Title <- as.factor(Title)
merged_set$family <- gsub("[, ]+[A-Za-z].*", "", merged_set$Name)
sorted_merged_set <- merged_set[with(merged_set, order(family, Pclass, Embarked, SibSp, Parch, Ticket)),]
familyGroup <- numeric()
familyGroup[1] <- 1
familyCount <- 1
for (i in 2:nrow(sorted_merged_set)){
if ((sorted_merged_set$family[i] == sorted_merged_set$family[i - 1]) &
((sorted_merged_set$Pclass[i] == sorted_merged_set$Pclass[i-1])) &
((sorted_merged_set$Embarked[i] == sorted_merged_set$Embarked[i-1])) &
((sorted_merged_set$SibSp[i] != 0) | (sorted_merged_set$Parch[i] !=0)) &
((sorted_merged_set$SibSp[i-1] != 0) | (sorted_merged_set$Parch[i-1] !=0))){
familyGroup[i] <- familyGroup[i-1]
}
else{
familyCount = familyCount + 1
familyGroup[i] <- familyCount
}
}
#View(data.frame(sorted_merged_set[,c("Name", "Sex", "Age", "SibSp", "Parch", "Embarked", "Ticket", "family")],familyGroup))
sorted_merged_set$familyGroup <- familyGroup
t <- table(sorted_merged_set$familyGroup)
t
t
t[sorted_merged_set$familyGroup]
sorted_merged_set$familySize <- t[sorted_merged_set$familyGroup]
sorted_merged_set$familyGroupSize <- paste(sorted_merged_set$family, t[sorted_merged_set$familyGroup])
sorted_merged_set$familyGroupSize[sorted_merged_set$familySize <= 2] <- "Small Family"
sorted_merged_set$familyGroupSize <- factor(sorted_merged_set$familyGroupSize)
head(sorted_merged_set)
str(sorted_merged_set)
na_Survived <- is.na(sorted_merged_set$Survived)
sorted_train <- sorted_merged_set[!na_Survived,]
sorted_test <- sorted_merged_set[na_Survived,]
train <- sorted_train[with(sorted_train, order(PassengerId)),]
test <- sorted_test[with(sorted_test, order(PassengerId)),]
train <- subset(train, select= -c(PassengerId, Name, Ticket, Cabin, family,
familyGroup, familySize))
head(train)
test <- subset(test, select= -c(Survived, Name, Ticket, Cabin, family,
familyGroup, familySize))
train$Survived <- factor(train$Survived, levels = c("0", "1"),
labels = c("Not_Survived", "Survived"))
str(train)
str(test)
library(ggplot2)
library(rattle)
library(caret)
library(rpart)
na_Embarked <- which(is.na(train$Embarked))
train[na_Embarked,]
df <- train[train$Fare < 100 & train$Fare > 50 & train$Pclass == 1,]
qplot(df$Age, df$Fare, color=df$Embarked)
# We observe the two observations(in black) in the plot.
# One of the observations(Age=38) lies near two blue ('S') points and hence we'll mark
# that as blue ('S') too.
train[na_Embarked[1],c("Embarked")] <- 'S'
# The other(Age=62) lies near a Red('C') point and we'll mark it as Red('C').
train[na_Embarked[2],c("Embarked")] <- 'C'
# If there had been more than 2 points, we might have used a classifier to
na_Age <- which(is.na(train$Age))
train.woNA <- train[-na_Age,]
train.na <- train[na_Age,]
set.seed(123)
fit1 <- lm(Age ~ Pclass + Sex + SibSp + Parch + Fare + Embarked + Title +
familyGroupSize, data=train.woNA)
predFit1 <- predict(fit1, train.woNA[,-c(1, 4)])
set.seed(123)
fit2 <- lm(Age ~ Pclass + Sex + SibSp + Parch + Fare + Embarked + Title,
data=train.woNA)
predFit2 <- predict(fit2, subset(train.woNA, select=c(Pclass, Sex, SibSp, Parch,
Fare, Embarked, Title)))
set.seed(123)
fit3 <- lm(Age ~ Pclass + Sex + SibSp + Parch + Fare + Title + familyGroupSize,
data=train.woNA)
predFit3 <- predict(fit3, subset(train.woNA, select=c(Pclass, Sex, SibSp, Parch,
Fare, Title, familyGroupSize)))
str(train)
set.seed(123)
fit4 <- lm(Age ~ Pclass + Sex + SibSp + Parch + Fare + Title, data=train.woNA)
predFit4 <- predict(fit4, subset(train.woNA, select=c(Pclass, Sex, SibSp, Parch,
Fare, Title)))
set.seed(123)
fit5 <- lm(formula = Age ~ Pclass + SibSp + Parch + Fare + Embarked + Title +
Parch:Title + SibSp:Parch, data = train.woNA)
predFit5 <- predict(fit5, subset(train.woNA, select=c(Pclass, SibSp, Parch,
Fare, Embarked, Title)))
set.seed(123)
# Using step function
step(fit1, ~.^2)
par(mfrow=c(2,2))
plot(fit5)
par(mfrow=c(1,1))
set.seed(123)
fit6 <- train(Age ~., data=train.woNA[,-c(1, 10)], method="rf")
predFit6 <- predict(fit6, subset(train.woNA, select=c(Pclass, Sex, SibSp, Parch,
Fare, Embarked, Title)))
set.seed(123)
fit7 <- rpart(Age ~ ., data=train.woNA[, -1], method="anova")
predFit7 <- predict(fit7, subset(train.woNA, select=c(Pclass, Sex, SibSp, Parch,
Fare, Embarked, Title,
familyGroup)))
fancyRpartPlot(fit7)
set.seed(123)
fit7 <- rpart(Age ~ ., data=train.woNA[, -1], method="anova")
predFit7 <- predict(fit7, subset(train.woNA, select=c(Pclass, Sex, SibSp, Parch,
Fare, Embarked, Title,
familyGroupSize)))
fancyRpartPlot(fit7)
df <- data.frame(predFit1, predFit2, predFit3, predFit4, predFit5, predFit6,
predFit7, train.woNA$Age)
age_Ensemble_df <- data.frame(pStep=predFit5, pForest=predFit6, pTree=predFit7,
Age=train.woNA$Age)
set.seed(123)
fit8 <- train(Age ~., method="gbm", data=age_Ensemble_df)
predFit8 <- predict(fit8, age_Ensemble_df[,-4])
df <- data.frame(predFit5, predFit6, predFit7, predFit8, train.woNA$Age)
View(df)
anova(fit1)
anova(fit1, fit2)
anova(fit1, fit3)
anova(fit1, fit2, fit3, fit4)
na_age_pred5 <- predict(fit5, train.na[,-c(4, 10)])
na_age_pred6 <- predict(fit6, train.na[,-c(4, 10)])
na_age_pred7 <- predict(fit7, train.na[,-4])
na_age_Ensemble_df <- data.frame(pStep=na_age_pred5, pForest=na_age_pred6,
pTree=na_age_pred7)
age_predictions <- predict(fit8, na_age_Ensemble_df)
# sum(age_predictions < 0)
train$Age[na_Age] <- age_predictions
sum(age_predictions < 0)
train$AgeGroup <- cut(train$Age, breaks = c(0, 8, 13, 18, 60, Inf), labels = c("Child", "Teenager", "Young Adult", "Adult", "Elder"), right=FALSE)
prop.table(table(train$AgeGroup, train$Survived),1)
ggplot(data=train, aes(AgeGroup, fill=Survived)) + geom_histogram(binwidth=1)
train <- subset(train, select=-AgeGroup)
set.seed(123) # setting seed for reproducibility
# We first divide the training set into two parts in 60:40 ratio.
inTrain <- createDataPartition(y=train$Survived, p = 0.6, list=FALSE)
training.train <- train[inTrain,]
rest_train <- train[-inTrain,]
set.seed(123) # setting seed for reproducibility
# We now divide the rest of the training set into two parts in 50:50 ratio.
# This splits the original training set in a 60:20:20 ratio.
inTest <- createDataPartition(y=rest_train$Survived, p = 0.5, list=FALSE)
# 20% data for validation set to select best classifier
training.classifier_valid <- rest_train[inTest,]
# 20% data for validation set to calculate out-of-sample errors
training.oos_valid <- rest_train[-inTest,]
library(klaR)
set.seed(123)
tree_Model <- train(Survived ~ ., data=training.train, method="rpart")
pred_Tree <- predict(tree_Model, newdata=training.classifier_valid[,-1])
conf_Tree <- confusionMatrix(pred_Tree, training.classifier_valid$Survived)
# Decision Tree Plot
library(rattle)
fancyRpartPlot(tree_Model$finalModel)
na_Age <- which(is.na(test$Age))
test.na <- test[na_Age,]
na_age_Ensemble_df <- data.frame(pStep=na_age_pred5, pForest=na_age_pred6,
pTree=na_age_pred7)
age_predictions <- predict(fit8, na_age_Ensemble_df)
test_na_age_pred5 <- predict(fit5, test.na[,-c(1, 4, 10)])
test_na_age_pred6 <- predict(fit6, test.na[,-c(1, 4, 10)])
test_na_age_pred7 <- predict(fit7, test.na[,-c(1, 4)])
test_na_age_Ensemble_df <- data.frame(pStep=test_na_age_pred5,
pForest=test_na_age_pred6,
pTree=test_na_age_pred7)
test_age_predictions <- predict(fit8, test_na_age_Ensemble_df)
# sum(test_age_predictions < 0)
test$Age[na_Age] <- test_age_predictions
summary(test)
str(test)
library(party)
set.seed(123)
fit <- cforest(Survived ~ ., data = train, controls=cforest_unbiased(ntree=2000, mtry=3))
Prediction <- predict(fit, test, OOB=TRUE, type = "response")
set.seed(415)
fit <- cforest(Survived ~ ., data = train, controls=cforest_unbiased(ntree=2000, mtry=3))
Prediction <- predict(fit, test, OOB=TRUE, type = "response")
Prediction
varImpPlot(fit)
final_pred <- as.numeric(pred_Forest_test=="Survived")
df <- data.frame(PassengerId=test$PassengerId, Survived=final_pred)
final_pred <- as.numeric(Prediction=="Survived")
df <- data.frame(PassengerId=test$PassengerId, Survived=final_pred)
write.csv(df, file="prediction_party_rf.csv", row.names=FALSE)
head(df)
set.seed(123)
forest_Model <- train(Survived ~ ., data=train, method="rf")
pred_Forest_test <- predict(forest_Model, newdata=test)
plot(forest_Model)
imp <- varImp(forest_Model)
featureImportance <- data.frame(Feature=row.names(imp), Importance=imp[,1])
imp
featureImportance <- data.frame(Feature=row.names(imp), Importance=imp)
featureImportance <- data.frame(Feature=row.names(imp), Importance=imp[,1])
imp$importance
featureImportance <- data.frame(Feature=row.names(imp), Importance=imp$importance)
imp
imp$model
imp[1]
imp[2]
featureImportance <- data.frame(Feature=row.names(imp), Importance=imp[1])
imp[,1]
varImpPlot(forest_Model)
final_pred <- as.numeric(pred_Forest_test=="Survived")
df <- data.frame(PassengerId=test$PassengerId, Survived=final_pred)
write.csv(df, file="prediction_rf.csv", row.names=FALSE)
set.seed(123)
tree_Model <- train(Survived ~ ., data=train, method="rpart")
pred_Tree_test <- predict(tree_Model, newdata=test)
fancyRpartPlot(tree_Model$finalModel)
final_pred <- as.numeric(pred_Tree_test=="Survived")
df <- data.frame(PassengerId=test$PassengerId, Survived=final_pred)
write.csv(df, file="prediction_tree.csv", row.names=FALSE)
head(train)
cont <- rpart.control(minsplit=50, cp=0)
my_tree_three <- rpart(formula=Survived ~ ., data=train, method="class", control=cont)
pred_tree_test <- predict(my_tree_three, newdata=test, type="class")
fancyRpartPlot(my_tree_three)
final_pred <- as.numeric(pred_tree_test=="Survived")
df <- data.frame(PassengerId=test$PassengerId, Survived=final_pred)
write.csv(df, file="prediction_tree_control.csv", row.names=FALSE)
fit <- glm(Survived ~., data=train, family="binomial")
step(fit, ~.^2)
fit <- glm(formula = Survived ~ Pclass + Sex + Age + SibSp + Parch +
Fare + Embarked + Title + Pclass:Sex + SibSp:Title + Age:Embarked +
Parch:Embarked + Pclass:Fare + Age:Fare + Age:SibSp + Age:Parch,
family = "binomial", data = train)
pred_glm_test <- predict(fit, newdata=test, type="response")
df <- data.frame(PassengerId=test$PassengerId, Survived=pred_glm_test )
write.csv(df, file="prediction_glm.csv", row.names=FALSE)
pred_glm_test
k <- numeric()
k <- numeric()
for (i in seq(0.4, 0.6, 0.01)){
a <- table(train[pred_glm_train > i,"Survived"])
b <- table(train[pred_glm_train <= i,"Survived"])
k <- c(k, (a[1]+b[2])/(a[2]+b[1]))
}
k[order(k)]
pred_glm_train <- predict(fit, newdata=train, type="response")
k <- numeric()
for (i in seq(0.4, 0.6, 0.01)){
a <- table(train[pred_glm_train > i,"Survived"])
b <- table(train[pred_glm_train <= i,"Survived"])
k <- c(k, (a[1]+b[2])/(a[2]+b[1]))
}
k[order(k)]
order(k)
i = 0.54
a <- table(train[pred_glm_train > i,"Survived"])
b <- table(train[pred_glm_train <= i,"Survived"])
(a[1]+b[2])/(a[2]+b[1])
df <- read.csv("prediction_manual_boost.csv")
df <- read.csv("prediction_manual_boost_test_set.csv")
df$Survived[(df$Glm + df$Rforest + df$Tree) >= 2] <- 1
df$Survived[!(df$Glm + df$Rforest + df$Tree) >= 2] <- 0
df <- df[,c("PassengerId", "Survived")]
head(df)
df$Rforest[df$Rforest==0] <- -1
df$voteRf[df$voteRf==0] <- -1
df$partyRf[df$partyRf==0] <- -1
head(df)
df$Survived[(df$Rforest + df$voteRf + df$partyRf) >= 0] <- 1
df$Survived[!(df$Glm + df$Rforest + df$Tree) >= 0] <- 0
head(df)
df$Survived[!(df$Rforest + df$voteRf + df$partyRf) >= 0] <- 0
head(df)
df$Survived[!(df$Rforest + df$voteRf + df$partyRf) >= 0] <- -1
head(df)
sum(which(df$voteRf == df$Survived))
which(df$voteRf == df$Survived)
which(!df$voteRf == df$Survived)
df$voteRf == df$Survived
sum(df$voteRf == df$Survived)
df$Survived[(df$Rforest + df$voteRf + (0.5*df$partyRf)) >= 0] <- 1
df$Survived[!(df$Rforest + df$voteRf + (0.5*df$partyRf)) >= 0] <- -1
df$Survived[!(df$Rforest + df$voteRf + (0.5*df$partyRf)) >= 0] <- 0
df$Survived[(df$Rforest + df$voteRf + (1.5*df$partyRf)) >= 0] <- 1
df$Survived[!(df$Rforest + df$voteRf + (1.5*df$partyRf)) >= 0] <- 0
head(df)
df$Survived[!(df$Rforest + df$voteRf + (1.5*df$partyRf)) >= 0] <- -1
sum(df$voteRf == df$Survived)
df$Survived[((0.5*df$Rforest) + df$voteRf + (1.5*df$partyRf)) >= 0] <- 1
df$Survived[!((0.5*df$Rforest) + df$voteRf + (1.5*df$partyRf)) >= 0] <- -1
sum(df$voteRf == df$Survived)
head(df)
df$Survived[((0.5*df$Rforest) + df$voteRf + (1.5*df$partyRf)) > 0] <- 1
df$Survived[!((0.5*df$Rforest) + df$voteRf + (1.5*df$partyRf)) > 0] <- -1
head(df)
sum(df$voteRf == df$Survived)
sum(df$partyRf == df$Survived)
df <- read.csv("prediction_manual_boost_test_set.csv")
head(df)
(df$Rforest * df$voteRf + df$partyRf) == 0
df$Survived[(df$Rforest * df$voteRf + df$partyRf) == 0] <- 0
df$Survived[!((df$Rforest * df$voteRf + df$partyRf) == 0)] <- 1
head(Df)
head(df)
sum(df$voteRf == df$Survived)
df$Survived[(df$Rforest * df$voteRf * df$partyRf) == 0] <- 0
df$Survived[!((df$Rforest * df$voteRf * df$partyRf) == 0)] <- 1
sum(df$voteRf == df$Survived)
sum(df$partyRf == df$Survived)
head(df)
df
sum(df$voteRf == df$Rforest)
df[(df$voteRf == df$Rforest)]
df[(df$voteRf == df$Rforest),]
df[(df$voteRf != df$Rforest),]
df$Survived[925, "Survived"] <- 1
df[925, "Survived"] <- 1
sum(df$voteRf == df$Rforest)
head(df)
df[925,]
df <- read.csv("prediction_manual_boost_test_set.csv")
df$Survived[(df$Rforest * df$voteRf * df$partyRf) == 0] <- 0
df$Survived[!((df$Rforest * df$voteRf * df$partyRf) == 0)] <- 1
df[32,]
df[(df$voteRf != df$Rforest),]
df[34, "Survived"] <- 1
sum(df$voteRf == df$Rforest)
sum(df$voteRf == df$Survived)
sum(df$Rforest == df$Survived)
sum(df$partyRf == df$Survived)
df <- df[,c("PassengerId", "Survived")]
write.csv(df, file="prediction_boost_vote.csv", row.names=FALSE)
df[34,]
