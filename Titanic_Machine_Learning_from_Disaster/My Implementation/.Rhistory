library(klaR)
library(klaR)
unloadNamespace(MASS)
library(MASS)
install.packages("forecast", repos=c("http://rstudio.org/_packages", "http://cran.rstudio.com"))
install.packages("MASS", repos=c("http://rstudio.org/_packages", "http://cran.rstudio.com"))
install.packages("MASS", repos = c("http://rstudio.org/_packages",
"http://cran.rstudio.com"))
install.packages("MASS", repos = c("http://rstudio.org/_packages",
)
)
library(klaR)
library(ggplot2)
library(caret)
set.seed(123)
naiveB_Model <- NaiveBayes(Survived ~ ., data=training.train)
pred_naiveB <- predict(naiveB_Model, newdata=training.classifier_valid[,-1])
conf_naiveB <- confusionMatrix(pred_naiveB$class, training.classifier_valid$Survived)
df_Ensemble <- data.frame(pTree=pred_Tree, pForest=pred_Forest,
pNaive=pred_naiveB$class,
Survived=training.classifier_valid$Survived)
set.seed(123)
ensemble_Model <- train(Survived ~., method="gbm", data=df_Ensemble)
pred_Ensemble <- predict(ensemble_Model, df_Ensemble[,-4])
conf_Ensemble <- confusionMatrix(pred_Ensemble, df_Ensemble$Survived)
set.seed(123)
boost_Model <- train(Survived ~., method="gbm", data=training.train)
pred_Boost <- predict(boost_Model, newdata=training.classifier_valid[,-1])
conf_Boost <- confusionMatrix(pred_Boost, training.classifier_valid$Survived)
compare_df <- data.frame(Accuracy = c(conf_Tree$overall[1],
conf_Forest$overall[1],
conf_naiveB$overall[1],
conf_Ensemble$overall[1],
conf_Boost$overall[1]),
row.names = c("rpart", "rf", "NaiveB", "Ensemble", "Boost"))
compare_df
pred_Tree_oos <- predict(tree_Model, newdata=training.oos_valid[,-1])
conf_Tree_oos <- confusionMatrix(pred_Tree_oos, training.oos_valid$Survived)
pred_Forest_oos <- predict(forest_Model, newdata=training.oos_valid[,-1])
conf_Forest_oos <- confusionMatrix(pred_Forest_oos, training.oos_valid$Survived)
pred_naiveB_oos <- predict(naiveB_Model, newdata=training.oos_valid[,-1])
conf_naiveB_oos <- confusionMatrix(pred_naiveB_oos$class, training.oos_valid$Survived)
df_ensemble_oos <- data.frame(pTree=pred_Tree, pForest=pred_Forest,
pNaive=pred_naiveB$class,
Survived=training.oos_valid$Survived)
pred_Ensemble_oos <- predict(ensemble_Model, df_ensemble_oos[,-4])
conf_Ensemble_oos <- confusionMatrix(pred_Ensemble_oos, df_ensemble_oos$Survived)
pred_Boost_oos <- predict(boost_Model, newdata=training.oos_valid[,-1])
conf_Boost_oos <- confusionMatrix(pred_Boost_oos, training.oos_valid$Survived)
compare_df_oos <- data.frame(Accuracy = c(conf_Tree_oos$overall[1],
conf_Forest_oos$overall[1],
conf_naiveB_oos$overall[1],
conf_Ensemble_oos$overall[1],
conf_Boost_oos$overall[1]),
row.names = c("rpart", "rf", "NaiveB", "Ensemble", "Boost"))
compare_df_oos
dim(pred_Tree)
pred_Tree
length(pred_Tree)
length(pred_Forest)
length(pred_naiveB$class)
pred_Tree_oos <- predict(tree_Model, newdata=training.oos_valid[,-1])
conf_Tree_oos <- confusionMatrix(pred_Tree_oos, training.oos_valid$Survived)
pred_Forest_oos <- predict(forest_Model, newdata=training.oos_valid[,-1])
conf_Forest_oos <- confusionMatrix(pred_Forest_oos, training.oos_valid$Survived)
pred_naiveB_oos <- predict(naiveB_Model, newdata=training.oos_valid[,-1])
conf_naiveB_oos <- confusionMatrix(pred_naiveB_oos$class, training.oos_valid$Survived)
df_ensemble_oos <- data.frame(pTree=pred_Tree_oos, pForest=pred_Forest_oos,
pNaive=pred_naiveB_oos$class,
Survived=training.oos_valid$Survived)
pred_Ensemble_oos <- predict(ensemble_Model, df_ensemble_oos[,-4])
conf_Ensemble_oos <- confusionMatrix(pred_Ensemble_oos, df_ensemble_oos$Survived)
pred_Boost_oos <- predict(boost_Model, newdata=training.oos_valid[,-1])
conf_Boost_oos <- confusionMatrix(pred_Boost_oos, training.oos_valid$Survived)
compare_df_oos <- data.frame(Accuracy = c(conf_Tree_oos$overall[1],
conf_Forest_oos$overall[1],
conf_naiveB_oos$overall[1],
conf_Ensemble_oos$overall[1],
conf_Boost_oos$overall[1]),
row.names = c("rpart", "rf", "NaiveB", "Ensemble", "Boost"))
compare_df_oos
head(train)
test_naive <- subset(inp_test, select = -c(Name, Ticket, Cabin))
test_naive$Pclass <- factor(test_naive$Pclass)
test_naive$Sex <- factor(test_naive$Sex)
test_naive$Embarked <- factor(test_naive$Embarked)
test <- subset(inp_test, select = -c(Name, Ticket, Cabin))
test$Pclass <- factor(test$Pclass)
teste$Sex <- factor(test$Sex)
test$Embarked <- factor(test$Embarked)
test <- subset(inp_test, select = -c(Name, Ticket, Cabin))
test$Pclass <- factor(test$Pclass)
test$Sex <- factor(test$Sex)
test$Embarked <- factor(test$Embarked)
head(test)
head(train)
summary(test)
which(is.na(test$Fare))
test$Fare[which(is.na(test$Fare))] <- 0
test$Fare[153]
test$Fare
na_Age <- which(is.na(test$Age))
test.na <- test[na_Age,]
test.na
anova(fit1, fit2, fit3, fit4, fit5, fit6)
train <-  subset(inp_train, select= -c(PassengerId))
# There are some columns which are more meaningful if we convert them to factors.
train$Survived <- factor(train$Survived, levels = c("0", "1"),
labels = c("Not_Survived", "Survived"))
train$Pclass <- factor(train$Pclass)
train$Sex <- factor(train$Sex)
train$Embarked <- factor(train$Embarked)
train <- subset(train, select= -c(Cabin, Name, Ticket))
na_Embarked <- which(is.na(train$Embarked))
train <- train[-na_Embarked,]
na_Age <- which(is.na(train$Age))
train.woNA <- train[-na_Age,]
train.na <- train[na_Age,]
library(caret)
set.seed(123)
fit1 <- lm(Age ~ Survived + Pclass + Sex + SibSp + Parch + Fare, data=train.woNA)
predFit1 <- predict(fit1, train.woNA[,-c(4, 8)])
set.seed(123)
fit2 <- lm(Age ~ Survived + Pclass + SibSp + Parch + Fare, data=train.woNA)
predFit2 <- predict(fit2, train.woNA[,c(1, 2, 5, 6, 7)])
set.seed(123)
fit3 <- lm(Age ~ Survived + Pclass + SibSp + Fare, data=train.woNA)
predFit3 <- predict(fit3, train.woNA[,c(1, 2, 5, 7)])
set.seed(123)
fit4 <- lm(Age ~ Pclass + SibSp + Fare, data=train.woNA)
predFit4 <- predict(fit4, train.woNA[,c(2, 5, 7)])
set.seed(123)
# Using step function
step(fit1, ~.^2)
set.seed(123)
fit5 <- lm(formula = Age ~ Survived + Pclass + Sex + SibSp + Parch +
Fare + Survived:Parch + Survived:SibSp + Sex:Parch + Pclass:Sex +
Survived:Sex + Survived:Fare + Survived:Pclass + Parch:Fare,
data = train.woNA)
predFit5 <- predict(fit5, train.woNA)
anova(fit1, fit2, fit3, fit4, fit5)
plot(fit5)
plot(fit5)
par(mfrow=c(2,2))
plot(fit5)
set.seed(123)
fit6 <- train(Age ~., data=train.woNA, method="rf")
predFit6 <- predict(fit6, train.woNA)
df <- data.frame(predFit1, predFit2, predFit3, predFit4, predFit5, predFit6, train.woNA$Age)
View(df)
age_predictions <- predict(fit6, train.na[,-c(4, 8)])
age_predictions <- predict(fit6, train.na[,-4])
sum(age_predictions < 0)
sum(predict(fit6, train.na[,-c(4,8)]) < 0)
sum(predict(fit5, train.na[,-c(4,8)]) < 0)
train$Age[na_Age] <- age_predictions
age_predictions
library(ggplot2)
library(gridExtra)
ggplot(data=train, aes(Survived)) + geom_histogram(binwidth=0.5) +
ggtitle("Fig.1: Histogram of Survivality")
ggplot(data=train, aes(x=Age, y=Sex, color=Survived)) +
geom_point(position="jitter") +
ggtitle("Fig.2: Comparision of Survivality by Age and Sex") +
xlab("Age (in years)")
ggplot(data=train, aes(x=SibSp, y=Age, color=Survived)) +
geom_point(position="jitter") +
ggtitle("Fig.3: Comparision of Survivality by Age and Sex") +
xlab("No. of Siblings") + ylab("Age (in years)")
library(scales)
ggplot(data=train, aes(x=SibSp, fill=Survived)) +
geom_bar(aes(y=(..count..)/sum(..count..))) +
scale_y_continuous(labels=percent) +
ggtitle("Fig.4: Percentage plot of no.of Siblings/Spouse and Survivality") +
xlab("Percentage of counts") + ylab("No. of Siblings")
ggplot(train, aes(x=SibSp, fill=Survived)) + geom_bar(position="fill") +
ggtitle("Fig.5: Relative Frequencies of no.of Siblings/Spouse and Survivality") +
xlab("No. of Siblings")
train$AgeGroup <- cut(train$Age, breaks = c(0, 8, 13, 18, 60, Inf), labels = c("Child", "Teenager", "Young Adult", "Adult", "Elder"), right=FALSE)
ggplot(data=train, aes(AgeGroup, fill=Survived)) + geom_histogram(binwidth=1)
library(caret)
train <- subset(train, select=-AgeGroup)
set.seed(123) # setting seed for reproducibility
# We first divide the training set into two parts in 60:40 ratio.
inTrain <- createDataPartition(y=train$Survived, p = 0.6, list=FALSE)
training.train <- train[inTrain,]
rest_train <- train[-inTrain,]
set.seed(123) # setting seed for reproducibility
# We now divide the rest of the training set into two parts in 50:50 ratio.
# This splits the original training set in a 60:20:20 ratio.
inTest <- createDataPartition(y=rest_train$Survived, p = 0.5, list=FALSE)
# 20% data for validation set to select best classifier
training.classifier_valid <- rest_train[inTest,]
# 20% data for validation set to calculate out-of-sample errors
training.oos_valid <- rest_train[-inTest,]
library(klaR)
set.seed(123)
tree_Model <- train(Survived ~ ., data=training.train, method="rpart")
pred_Tree <- predict(tree_Model, newdata=training.classifier_valid[,-1])
conf_Tree <- confusionMatrix(pred_Tree, training.classifier_valid$Survived)
# Decision Tree Plot
library(rattle)
fancyRpartPlot(tree_Model$finalModel)
par(mfrow=c(1,1))
fancyRpartPlot(tree_Model$finalModel)
set.seed(123)
forest_Model <- train(Survived ~ ., data=training.train, method="rf")
pred_Forest <- predict(forest_Model, newdata=training.classifier_valid[,-1])
conf_Forest <- confusionMatrix(pred_Forest, training.classifier_valid$Survived)
set.seed(123)
naiveB_Model <- NaiveBayes(Survived ~ ., data=training.train)
pred_naiveB <- predict(naiveB_Model, newdata=training.classifier_valid[,-1])
conf_naiveB <- confusionMatrix(pred_naiveB$class, training.classifier_valid$Survived)
df_Ensemble <- data.frame(pTree=pred_Tree, pForest=pred_Forest,
pNaive=pred_naiveB$class,
Survived=training.classifier_valid$Survived)
set.seed(123)
ensemble_Model <- train(Survived ~., method="gbm", data=df_Ensemble)
pred_Ensemble <- predict(ensemble_Model, df_Ensemble[,-4])
conf_Ensemble <- confusionMatrix(pred_Ensemble, df_Ensemble$Survived)
set.seed(123)
boost_Model <- train(Survived ~., method="gbm", data=training.train)
pred_Boost <- predict(boost_Model, newdata=training.classifier_valid[,-1])
conf_Boost <- confusionMatrix(pred_Boost, training.classifier_valid$Survived)
compare_df <- data.frame(Accuracy = c(conf_Tree$overall[1],
conf_Forest$overall[1],
conf_naiveB$overall[1],
conf_Ensemble$overall[1],
conf_Boost$overall[1]),
row.names = c("rpart", "rf", "NaiveB", "Ensemble", "Boost"))
compare_df
pred_Tree_oos <- predict(tree_Model, newdata=training.oos_valid[,-1])
conf_Tree_oos <- confusionMatrix(pred_Tree_oos, training.oos_valid$Survived)
pred_Forest_oos <- predict(forest_Model, newdata=training.oos_valid[,-1])
conf_Forest_oos <- confusionMatrix(pred_Forest_oos, training.oos_valid$Survived)
pred_naiveB_oos <- predict(naiveB_Model, newdata=training.oos_valid[,-1])
conf_naiveB_oos <- confusionMatrix(pred_naiveB_oos$class, training.oos_valid$Survived)
df_ensemble_oos <- data.frame(pTree=pred_Tree_oos, pForest=pred_Forest_oos,
pNaive=pred_naiveB_oos$class,
Survived=training.oos_valid$Survived)
pred_Ensemble_oos <- predict(ensemble_Model, df_ensemble_oos[,-4])
conf_Ensemble_oos <- confusionMatrix(pred_Ensemble_oos, df_ensemble_oos$Survived)
pred_Boost_oos <- predict(boost_Model, newdata=training.oos_valid[,-1])
conf_Boost_oos <- confusionMatrix(pred_Boost_oos, training.oos_valid$Survived)
compare_df_oos <- data.frame(Accuracy = c(conf_Tree_oos$overall[1],
conf_Forest_oos$overall[1],
conf_naiveB_oos$overall[1],
conf_Ensemble_oos$overall[1],
conf_Boost_oos$overall[1]),
row.names = c("rpart", "rf", "NaiveB", "Ensemble", "Boost"))
compare_df_oos
test <- subset(inp_test, select = -c(Name, Ticket, Cabin))
test$Pclass <- factor(test$Pclass)
test$Sex <- factor(test$Sex)
test$Embarked <- factor(test$Embarked)
test$Fare[which(is.na(test$Fare))] <- 0
na_Age <- which(is.na(test$Age))
test.na <- test[na_Age,]
head(test.na)
test <- subset(inp_test, select = -c(PassengerId, Name, Ticket, Cabin))
test$Pclass <- factor(test$Pclass)
test$Sex <- factor(test$Sex)
test$Embarked <- factor(test$Embarked)
test$Fare[which(is.na(test$Fare))] <- 0
na_Age <- which(is.na(test$Age))
test.na <- test[na_Age,]
head(test.na)
test <- subset(inp_test, select = -c(Name, Ticket, Cabin))
test$Pclass <- factor(test$Pclass)
test$Sex <- factor(test$Sex)
test$Embarked <- factor(test$Embarked)
test$Fare[which(is.na(test$Fare))] <- 0
na_Age <- which(is.na(test$Age))
test.na <- test[na_Age,]
head(test.na)
age_predictions <- predict(fit6, test.na[,-c(1, 4)])
train <-  subset(inp_train, select= -c(PassengerId))
# There are some columns which are more meaningful if we convert them to factors.
train$Survived <- factor(train$Survived, levels = c("0", "1"),
labels = c("Not_Survived", "Survived"))
train$Pclass <- factor(train$Pclass)
train$Sex <- factor(train$Sex)
train$Embarked <- factor(train$Embarked)
rm(list=ls())
path <- "C://Users//Abhijeet//Documents//GitHub//Kaggle//Titanic_Machine_Learning_from_Disaster//My Implementation"
if (getwd() != path) {setwd(path)}
# Step 1
## Fetching data from the training and testing datasets
inp_train <- read.csv(file="data/train.csv", header=TRUE, sep=",", quote="\"",
stringsAsFactors=FALSE, na.strings=c("NA",""))
inp_test <- read.csv(file="data/test.csv", header=TRUE, sep=",", quote="\"",
stringsAsFactors=FALSE, na.strings=c("NA",""))
train <-  subset(inp_train, select= -c(PassengerId))
# There are some columns which are more meaningful if we convert them to factors.
train$Survived <- factor(train$Survived, levels = c("0", "1"),
labels = c("Not_Survived", "Survived"))
train$Pclass <- factor(train$Pclass)
train$Sex <- factor(train$Sex)
train$Embarked <- factor(train$Embarked)
train <- subset(train, select= -c(Cabin, Name, Ticket))
na_Embarked <- which(is.na(train$Embarked))
train <- train[-na_Embarked,]
na_Age <- which(is.na(train$Age))
train.woNA <- train[-na_Age,]
train.na <- train[na_Age,]
library(caret)
set.seed(123)
fit1 <- lm(Age ~ Pclass + Sex + SibSp + Parch + Fare, data=train.woNA)
predFit1 <- predict(fit1, train.woNA[,-c(4, 8)])
anova(fit1)
set.seed(123)
# Using step function
step(fit1, ~.^2)
fit1 <- lm(Age ~ Pclass + Sex + SibSp + Parch + Fare + Embarked, data=train.woNA)
summary(fit1)
summary(train)
fit1 <- lm(Age ~ Pclass + Sex + SibSp + Parch + Fare + Embarked, data=train.woNA)
predFit1 <- predict(fit1, train.woNA[,-c(1, 4)])
anova(fit1)
summary(parch)
summary(fit1)
set.seed(123)
fit1 <- lm(Age ~ Pclass + Sex + SibSp + Parch + Fare + Embarked, data=train.woNA)
predFit1 <- predict(fit1, train.woNA[,-c(1, 4)])
step(fit1, ~.^2)
step(fit1, ~.^3)
step(fit1, ~.^2)
anova(fit1)
head(train.woNA)
set.seed(123)
fit2 <- lm(Age ~ Pclass + Sex + SibSp + Fare + Embarked, data=train.woNA)
predFit2 <- predict(fit2, train.woNA[,c(2, 3, 5, 7, 8)])
set.seed(123)
fit3 <- lm(Age ~ Pclass + Sex + SibSp + Fare, data=train.woNA)
predFit3 <- predict(fit3, train.woNA[,c(2, 3, 5, 7)])
set.seed(123)
fit4 <- lm(Age ~ Pclass + Sex + SibSp, data=train.woNA)
predFit4 <- predict(fit4, train.woNA[,c(2, 3, 5)])
set.seed(123)
fit5 <- lm(formula = Age ~ Pclass + Sex + SibSp + Parch + Fare + Embarked +
Pclass:Parch + Parch:Fare + Sex:Parch + Sex:Embarked + Pclass:SibSp +
SibSp:Fare + Pclass:Embarked, data = train.woNA)
predFit5 <- predict(fit5, train.woNA)
anova(fit1, fit2, fit3, fit4, fit5)
par(mfrow=c(2,2))
plot(fit5)
set.seed(123)
fit6 <- train(Age ~. - Survived, data=train.woNA, method="rf")
predFit6 <- predict(fit6, train.woNA[,-1])
fit6 <- train(Age ~., data=train.woNA[,-1], method="rf")
predFit6 <- predict(fit6, train.woNA[,-1])
set.seed(123)
fit6 <- train(Age ~., data=train.woNA[,-1], method="rf")
predFit6 <- predict(fit6, train.woNA)
plot(predFit6)
df <- data.frame(predFit1, predFit2, predFit3, predFit4, predFit5, predFit6,
train.woNA$Age)
View(df)
age_predictions <- predict(fit6, train.na[,-4])
sum(age_predictions < 0)
age_predictions <- predict(fit5, train.na[,-4])
sum(age_predictions < 0)
train$Age[na_Age] <- age_predictions
library(ggplot2)
library(gridExtra)
# histogram for Survived column.
ggplot(data=train, aes(Survived)) + geom_histogram(binwidth=0.5) +
ggtitle("Fig.1: Histogram of Survivality")
ggplot(data=train, aes(x=Age, y=Sex, color=Survived)) +
geom_point(position="jitter") +
ggtitle("Fig.2: Comparision of Survivality by Age and Sex") +
xlab("Age (in years)")
library(scales)
ggplot(data=train, aes(x=SibSp, fill=Survived)) +
geom_bar(aes(y=(..count..)/sum(..count..))) +
scale_y_continuous(labels=percent) +
ggtitle("Fig.4: Percentage plot of no.of Siblings/Spouse and Survivality") +
xlab("Percentage of counts") + ylab("No. of Siblings")
ggplot(train, aes(x=SibSp, fill=Survived)) + geom_bar(position="fill") +
ggtitle("Fig.5: Relative Frequencies of no.of Siblings/Spouse and Survivality") +
xlab("No. of Siblings")
train$AgeGroup <- cut(train$Age, breaks = c(0, 8, 13, 18, 60, Inf), labels = c("Child", "Teenager", "Young Adult", "Adult", "Elder"), right=FALSE)
ggplot(data=train, aes(AgeGroup, fill=Survived)) + geom_histogram(binwidth=1)
library(caret)
train <- subset(train, select=-AgeGroup)
set.seed(123) # setting seed for reproducibility
# We first divide the training set into two parts in 60:40 ratio.
inTrain <- createDataPartition(y=train$Survived, p = 0.6, list=FALSE)
training.train <- train[inTrain,]
rest_train <- train[-inTrain,]
set.seed(123) # setting seed for reproducibility
# We now divide the rest of the training set into two parts in 50:50 ratio.
# This splits the original training set in a 60:20:20 ratio.
inTest <- createDataPartition(y=rest_train$Survived, p = 0.5, list=FALSE)
# 20% data for validation set to select best classifier
training.classifier_valid <- rest_train[inTest,]
# 20% data for validation set to calculate out-of-sample errors
training.oos_valid <- rest_train[-inTest,]
head(train)
library(klaR)
par(mfrow=c(1,1))
# Decision Trees
set.seed(123)
tree_Model <- train(Survived ~ ., data=training.train, method="rpart")
pred_Tree <- predict(tree_Model, newdata=training.classifier_valid[,-1])
conf_Tree <- confusionMatrix(pred_Tree, training.classifier_valid$Survived)
# Decision Tree Plot
library(rattle)
fancyRpartPlot(tree_Model$finalModel)
set.seed(123)
forest_Model <- train(Survived ~ ., data=training.train, method="rf")
pred_Forest <- predict(forest_Model, newdata=training.classifier_valid[,-1])
conf_Forest <- confusionMatrix(pred_Forest, training.classifier_valid$Survived)
set.seed(123)
naiveB_Model <- NaiveBayes(Survived ~ ., data=training.train)
pred_naiveB <- predict(naiveB_Model, newdata=training.classifier_valid[,-1])
conf_naiveB <- confusionMatrix(pred_naiveB$class, training.classifier_valid$Survived)
df_Ensemble <- data.frame(pTree=pred_Tree, pForest=pred_Forest,
pNaive=pred_naiveB$class,
Survived=training.classifier_valid$Survived)
set.seed(123)
ensemble_Model <- train(Survived ~., method="gbm", data=df_Ensemble)
pred_Ensemble <- predict(ensemble_Model, df_Ensemble[,-4])
conf_Ensemble <- confusionMatrix(pred_Ensemble, df_Ensemble$Survived)
set.seed(123)
boost_Model <- train(Survived ~., method="gbm", data=training.train)
pred_Boost <- predict(boost_Model, newdata=training.classifier_valid[,-1])
conf_Boost <- confusionMatrix(pred_Boost, training.classifier_valid$Survived)
compare_df <- data.frame(Accuracy = c(conf_Tree$overall[1],
conf_Forest$overall[1],
conf_naiveB$overall[1],
conf_Ensemble$overall[1],
conf_Boost$overall[1]),
row.names = c("rpart", "rf", "NaiveB", "Ensemble", "Boost"))
compare_df
pred_Tree_oos <- predict(tree_Model, newdata=training.oos_valid[,-1])
conf_Tree_oos <- confusionMatrix(pred_Tree_oos, training.oos_valid$Survived)
pred_Forest_oos <- predict(forest_Model, newdata=training.oos_valid[,-1])
conf_Forest_oos <- confusionMatrix(pred_Forest_oos, training.oos_valid$Survived)
pred_naiveB_oos <- predict(naiveB_Model, newdata=training.oos_valid[,-1])
conf_naiveB_oos <- confusionMatrix(pred_naiveB_oos$class, training.oos_valid$Survived)
df_ensemble_oos <- data.frame(pTree=pred_Tree_oos, pForest=pred_Forest_oos,
pNaive=pred_naiveB_oos$class,
Survived=training.oos_valid$Survived)
pred_Ensemble_oos <- predict(ensemble_Model, df_ensemble_oos[,-4])
conf_Ensemble_oos <- confusionMatrix(pred_Ensemble_oos, df_ensemble_oos$Survived)
pred_Boost_oos <- predict(boost_Model, newdata=training.oos_valid[,-1])
conf_Boost_oos <- confusionMatrix(pred_Boost_oos, training.oos_valid$Survived)
compare_df_oos <- data.frame(Accuracy = c(conf_Tree_oos$overall[1],
conf_Forest_oos$overall[1],
conf_naiveB_oos$overall[1],
conf_Ensemble_oos$overall[1],
conf_Boost_oos$overall[1]),
row.names = c("rpart", "rf", "NaiveB", "Ensemble", "Boost"))
compare_df_oos
test <- subset(inp_test, select = -c(Name, Ticket, Cabin))
test$Pclass <- factor(test$Pclass)
test$Sex <- factor(test$Sex)
test$Embarked <- factor(test$Embarked)
test$Fare[which(is.na(test$Fare))] <- 0
na_Age <- which(is.na(test$Age))
test.na <- test[na_Age,]
age_predictions <- predict(fit6, test.na[,-c(1, 4)])
test$Age[na_Age] <- age_predictions
age_predictions
sum(age_predictions<0)
summary(test.na)
summary(test)
dim(test)
pred_Forest_test <- predict(forest_Model, newdata=test)
pred_Forest_test
test
final_pred <- as.numeric(pred_Forest_test=="Survived")
df <- data.frame(PassengerId=test$PassengerId, Survived=final_pred)
df
write.csv(df, file="prediction_rf.csv", row.names=FALSE))
write.csv(df, file="prediction_rf.csv", row.names=FALSE)
# Decision Tree
pred_Tree_test <- predict(tree_Model, newdata=test)
# converting factor to numeric(Not_Survived=0, Survived=1)
final_pred <- as.numeric(pred_Tree_test=="Survived")
df <- data.frame(PassengerId=test$PassengerId, Survived=final_pred)
write.csv(df, file="prediction_tree.csv", row.names=FALSE)
pred_naiveB_test <- predict(naiveB_Model, newdata=test)
# converting factor to numeric(Not_Survived=0, Survived=1)
final_pred <- as.numeric(pred_naiveB_test$class=="Survived")
df <- data.frame(PassengerId=test$PassengerId, Survived=final_pred)
write.csv(df, file="prediction_naiveB.csv", row.names=FALSE))
pred_naiveB_test <- predict(naiveB_Model, newdata=test)
# converting factor to numeric(Not_Survived=0, Survived=1)
final_pred <- as.numeric(pred_naiveB_test$class=="Survived")
df <- data.frame(PassengerId=test$PassengerId, Survived=final_pred)
write.csv(df, file="prediction_naiveB.csv", row.names=FALSE))
pred_naiveB_test <- predict(naiveB_Model, newdata=test)
# converting factor to numeric(Not_Survived=0, Survived=1)
final_pred <- as.numeric(pred_naiveB_test$class=="Survived")
df <- data.frame(PassengerId=test$PassengerId, Survived=final_pred)
write.csv(df, file="prediction_naiveB.csv", row.names=FALSE)
# Boost
df_Ensemble_test <- data.frame(pTree=pred_Tree_test, pForest=pred_Forest_test,
pNaive=pred_naiveB_test$class)
pred_Ensemble_test <- predict(ensemble_Model, newdata=df_Ensemble_test)
# converting factor to numeric(Not_Survived=0, Survived=1)
final_pred <- as.numeric(pred_Ensemble_test=="Survived")
df <- data.frame(PassengerId=test$PassengerId, Survived=final_pred)
write.csv(df, file="prediction_ensemble.csv", row.names=FALSE)
# Boost
pred_Boost_test <- predict(boost_Model, newdata=test)
# converting factor to numeric(Not_Survived=0, Survived=1)
final_pred <- as.numeric(pred_Boost_test=="Survived")
df <- data.frame(PassengerId=test$PassengerId, Survived=final_pred)
write.csv(df, file="prediction_boost.csv", row.names=FALSE)
